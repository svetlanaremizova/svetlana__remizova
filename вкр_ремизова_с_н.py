# -*- coding: utf-8 -*-
"""ВКР Ремизова С.Н.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kep14kkS0gt2UQT-dPdAYw6CW3iMfQlq
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns


import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.pylab as plt
from matplotlib import pyplot as plt
from matplotlib import pyplot


import pandas_profiling
from pandas import read_csv
from pandas.plotting import scatter_matrix


from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import roc_auc_score, recall_score, confusion_matrix
from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score, GridSearchCV, KFold
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.preprocessing import RobustScaler
from sklearn.preprocessing import Normalizer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler, PowerTransformer,MinMaxScaler
from sklearn.linear_model import ElasticNet
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeRegressor
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB



from scipy.sparse.linalg import svds
from imblearn.over_sampling import SMOTE, ADASYN


from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization, GlobalAveragePooling2D
import tensorflow.keras as keras
import tensorflow as tf
import tensorflow_datasets as tfds
from keras.wrappers.scikit_learn import KerasClassifier


from IPython.display import clear_output


import torch
from torch.autograd import Variable


# %matplotlib inline
# %config InlineBackend.figure_format = 'retina' # для более четкой отрисовки графиков

!pip install matplotlib

!pip install xlrd

import xlrd

df1 = pd.read_excel('/content/X_bp.xlsx')
df1.head(5)

df1.shape

df2 = pd.read_excel('/content/X_nup.xlsx')
df2.head()

df2.shape

df1.profile_report()

df2.profile_report()

df3_merged = pd.merge(df1, df2) 
 df3_merged.head()

df3_merged.shape

df3_merged.dtypes

df3_merged.isna().sum()

df3_merged.profile_report()

df3_merged.drop(['Плотность, кг/м3', 'Количество отвердителя, м.%',	'Содержание эпоксидных групп,%_2',	'Температура вспышки, С_2',	'Поверхностная плотность, г/м2', 'модуль упругости, ГПа','Потребление смолы, г/м2',	'Угол нашивки, град',	'Шаг нашивки', 'Плотность нашивки'], axis=1)

for col in df3_merged: # посмотрим на распределение числовых переменных
    plt.figure()
    sns.histplot(df3_merged[col])

sns.pairplot(df3_merged)

df3_merged.plot.box(title='Диаграмма "ящик с усами"')
plt.rcParams['figure.figsize']=10,15

sns.boxplot(y = df3_merged['Модуль упругости при растяжении, ГПа'])

sns.boxplot(x = df3_merged['Прочность при растяжении, МПа'])

fig, ax = plt.subplots(figsize=(12, 8))
sns.heatmap(df3_merged.corr(), annot=True, fmt='.3f', cmap = 'coolwarm', ax=ax);

fig, ax = plt.subplots(figsize=(18, 14))
sns.heatmap(df3_merged.corr(), annot=True, fmt='.3f', cmap = 'viridis', ax=ax);

#получим среднее и медианное значения данных в колонках
mean_and_50 = df3_merged.describe()
mean_and_50.loc[['mean', '50%']]
#в целом мы видим близкие друг к другу значения

df3_merged.mean()

# Вычисляем коэффициенты ранговой корреляции Кендалла. Статистической зависимости не наблюдаем.?
df3_merged.corr(method = 'kendall')

#Вычисляем коэффициенты корреляции Пирсона. Статистической зависимости не наблюдаем.
df3_merged.corr(method ='pearson')

# "Ящики с усами"(боксплоты) (первый вариант)
scaler = MinMaxScaler()
scaler.fit(df3_merged)
plt.figure(figsize = (20, 20))
plt.suptitle('Диаграммы "ящики с усами"', y = 0.9 ,
             fontsize = 30)
plt.boxplot(pd.DataFrame(scaler.transform(df3_merged)), labels = df3_merged.columns,patch_artist = True, meanline = True, vert = False, boxprops = dict(facecolor = 'g', color = 'y'),medianprops = dict(color = 'lime'), whiskerprops = dict(color="g"), capprops = dict(color = "black"), flierprops = dict(color = "y", markeredgecolor = "maroon"))
plt.show()

y = df3_merged['Модуль упругости при растяжении, ГПа']
x = df3_merged

x

y

np.array(x)

np.array(y)

"""Линейная регрессия"""

x_train, x_test, y_train, y_test = train_test_split(df3_merged.drop(['Модуль упругости при растяжении, ГПа'], axis=1), 
                                                    df3_merged['Модуль упругости при растяжении, ГПа'],
                                                    test_size=0.3
                                                   )

print(x_train.shape, x_test.shape)

x_train.describe()

scl = RobustScaler()
x_train_scl = scl.fit_transform(x_train)
x_test_scl = scl.transform(x_test)

model = ElasticNet(random_state=17)
cv = KFold(n_splits=7) # схема для кросс-валидации

cv_score = cross_val_score(model, 
                           x_train, y_train, 
                           scoring='neg_mean_absolute_error', 
                           cv=cv, n_jobs=-1) # прогоняем модель на кросс-валидации
print('MAE на кросс-валидации: %.3f+-%.3f'% (abs(np.mean(cv_score)), np.std(cv_score)))

params = {'alpha': (0.1, 0.5, 1), 
          'l1_ratio': (0.1, 0.5, 0.9)}
model_grid = GridSearchCV(model, 
                          param_grid=params, 
                          scoring='neg_mean_absolute_error', 
                          n_jobs=-1, cv=cv)
model_grid.fit(x_train, y_train)

print('Лучшая модель на кросс-валидации с параметрами {} и MAE {}'.format(model_grid.best_params_, 
                                                                        abs(model_grid.best_score_)))

best_model = model_grid.best_estimator_

best_model.fit(x_train_scl, y_train)
print('MAE на тестовой выборке: %.3f' % mean_absolute_error(y_test, best_model.predict(x_test_scl)))

y = df3_merged['Прочность при растяжении, МПа']
x = df3_merged

x

y

np.array(x)

np.array(y)

x_train, x_test, y_train, y_test = train_test_split(df3_merged.drop(['Прочность при растяжении, МПа'], axis=1), 
                                                    df3_merged['Прочность при растяжении, МПа'],
                                                    test_size=0.3,
                                                    random_state=20,
                                                    shuffle=True
                                                   )

print(x_train.shape, x_test.shape)

print('Размер тренировочного датасета: {}\nРазмер тестового датасета:{}'.format(x_train.shape, x_test.shape))

x_train.describe()

scl = RobustScaler()
x_train_scl = scl.fit_transform(x_train)
x_test_scl = scl.transform(x_test)

model = ElasticNet(random_state=17)
cv = KFold(n_splits=7) # схема для кросс-валидации

cv_score = cross_val_score(model, 
                           x_train, y_train, 
                           scoring='neg_mean_absolute_error', 
                           cv=cv, n_jobs=-1) # прогоняем модель на кросс-валидации
print('MAE на кросс-валидации: %.3f+-%.3f'% (abs(np.mean(cv_score)), np.std(cv_score)))

params = {'alpha': (0.1, 0.5, 1), 
          'l1_ratio': (0.1, 0.5, 0.9)}
model_grid = GridSearchCV(model, 
                          param_grid=params, 
                          scoring='neg_mean_absolute_error', 
                          n_jobs=-1, cv=cv)
model_grid.fit(x_train, y_train)

print('Лучшая модель на кросс-валидации с параметрами {} и MAE {}'.format(model_grid.best_params_, 
                                                                        abs(model_grid.best_score_)))

best_model = model_grid.best_estimator_

best_model.fit(x_train_scl, y_train)
print('MAE на тестовой выборке: %.3f' % mean_absolute_error(y_test, best_model.predict(x_test_scl)))

"""Дерево решений"""

df3_merged = pd.read_excel('X_bp.xlsx', header=None) # загружаем данные
df3_merged.columns = ['1_'+str(i) for i in range(df3_merged.shape[1]-1)] + ['Прочность при растяжении, МПа'] # пронумеруем признаки и обозначим целевой признак

df3_merged

x_train, x_test, y_train, y_test = train_test_split(df3_merged.drop(['Прочность при растяжении, МПа'], axis=1), 
                                                    df3_merged['Прочность при растяжении, МПа'],
                                                    test_size=0.3,
                                                    random_state=20,
                                                    shuffle=True
                                                   )

print('Размер тренировочной выборки: {}\nРазмер тестовой выборки: {}'.format(x_train.shape, x_test.shape))

""" нейронная сеть 

"""

df = pd.read_excel('/content/X_bp.xlsx')
df.head(5)

for col in df.select_dtypes(include='O').columns: #  для всех категориальных признаков
    print(col)
    print(df[col].value_counts(),'\n')

df.drop(['Количество отвердителя, м.%', 'Плотность, кг/м3', 'Количество отвердителя, м.%', 'Содержание эпоксидных групп,%_2', 'Температура вспышки, С_2', 'модуль упругости, ГПа', 'Поверхностная плотность, г/м2', 'Потребление смолы, г/м2'], axis=1)

df.isna().sum()

df.value_counts()

num_cols = ['Соотношение матрица-наполнитель', 'Модуль упругости при растяжении, ГПа', 'Прочность при растяжении, МПа']

x_train, x_test, y_train, y_test = train_test_split(df.drop(['Соотношение матрица-наполнитель'], axis=1),
                                                    df['Соотношение матрица-наполнитель'],
                                                    test_size=0.3
                                                   )

transformer = PowerTransformer(standardize=True)
x_train = transformer.fit_transform(x_train) # нормализируем и стандартизируем выборку
x_test = transformer.transform(x_test) # нормализируем и стандартизируем выборку
y_train = np.array(y_train)
y_test = np.array(y_test)

x_train.shape, x_test.shape

"""Бинарная и множественная классификация"""

input_ = keras.layers.Input(shape=(x_train.shape[1],)) # входной слой
x = keras.layers.Dense(30, activation='relu')(input_) # полносвязный слой
x = keras.layers.Dense(20, activation='relu')(x) # полносвязный слой
output_ = keras.layers.Dense(1, activation='sigmoid')(x) # выходной слой

model = keras.models.Model(input_, output_) # определем вход и выход моедли

model.compile(loss = 'binary_crossentropy', # определяем метрики и алгоритм оптимизации
              optimizer = 'adam',
              metrics = 'accuracy'
             )

history = model.fit(x_train, y_train, 
                    epochs=100, 
                    batch_size=30, 
                    validation_split=0.3,
                    callbacks=keras.callbacks.EarlyStopping(patience=5)
                   ) # сохраняем историю тренировки

pd.DataFrame(history.history).plot(); # модель постепенно переобучается

print('MAE на тестовой выборке: %.3f' %mean_absolute_error(y_test, model.predict(x_test)))

"""Нейронная сеть для задач регрессии"""

input_ = keras.layers.Input(shape=(x_train.shape[1],)) # входной слой
x = keras.layers.Dense(400, activation='relu')(input_) # полносвязный слой
x = keras.layers.Dropout(0.3)(x)
x = keras.layers.Dense(200, activation='relu')(x) # полносвязный слой
x = keras.layers.Dropout(0.2)(x)
x = keras.layers.Dense(100, activation='relu')(x) # полносвязный слой
x = keras.layers.Dropout(0.2)(x)
x = keras.layers.Dense(50, activation='relu')(x) # полносвязный слой
x = keras.layers.Dropout(0.2)(x)
x = keras.layers.Dense(20, activation='relu')(x) # полносвязный слой
output_ = keras.layers.Dense(1)(x) # выходной слой

model = keras.models.Model(input_, output_) # определем въод и выход моедли

early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', 
                                           patience=6) # ранняя остановка
reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', 
                                              factor=0.25, 
                                              patience=3, 
                                              verbose=1) # редактирование скорости обучения

model.compile(loss = 'mse', # определяем метрики и алгоритм оптимизации
              optimizer = 'adam',
              metrics = ['mae']
             )

history = model.fit(x_train, 
                    y_train, 
                    epochs=100,
                    batch_size=70,
                    validation_split=0.2,
                    callbacks = [early_stop, reduce_lr],
                    shuffle=False
                   ) # сохраняем историю тренировки

pd.DataFrame(history.history).iloc[:, :4].plot()

print('MAE на тестовой выборке: %.3f' %mean_absolute_error(y_test, model.predict(x_test)))

"""Рекомендательные системы"""

#Прогнозируем модуль упругости при растяжении, ГПа
#разбиваем на тестовую, тренировочную выборки, выделяя предикторы и целевые переменные
normalizer = Normalizer()
res = normalizer.fit_transform(df3_merged)
df3_merged_norm_n = pd.DataFrame(res, columns = df3_merged.columns)
x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(
    df3_merged_norm_n.loc[:, df3_merged_norm_n.columns != 'Модуль упругости при растяжении, ГПа'],
    df3_merged[['Модуль упругости при растяжении, ГПа']],
       test_size = 0.3,
    random_state = 42)

# Проверка правильности разбивки
df3_merged_norm_n.shape[0] - x_train.shape[0] - x_test.shape[0]

x_train_2.head()

y_train_2

y_train_2.shape

# Функция для сравнения результатов предсказаний с моделью, выдающей среднее значение по тестовой выборке
def mean_model(y_test_2):
    return [np.mean(y_test_2) for _ in range(len(y_test_2))]
y_2_pred_mean = mean_model(y_test_2)

#Результаты модели, выдающей среднее значение
mse_lin_elast2_mean = mean_squared_error(y_test_2, y_2_pred_mean)
print("MAE for mean target: ", mean_absolute_error(y_test_2, y_2_pred_mean))
print("MSE for mean target: ", mse_lin_elast2_mean)
print("RMSE for mean target: ", np.sqrt(mse_lin_elast2_mean))

#построение модели и вузуализация метода случайный лес
rfr2 = RandomForestRegressor(n_estimators = 15,max_depth = 7, random_state = 33)
rfr2.fit(x_train_2, y_train_2.values)
y2_pred_forest = rfr2.predict(x_test_2)
mae_rfr2 = mean_absolute_error(y2_pred_forest, y_test_2)
mse_rfr_elast2 = mean_squared_error(y_test_2,y2_pred_forest)
print('Random Forest Regressor Results Train:')
print("Test score: {:.2f}".format(rfr2.score(x_train_2, y_train_2))) # Скор для тренировочной выборки
print('Random Forest Regressor Results:')
print('RF_MAE: ', round(mean_absolute_error(y_test_2, y2_pred_forest)))
print('RF_MSE: {:.2f}'.format(mse_rfr_elast2))
print("RF_RMSE: {:.2f}".format (np.sqrt(mse_rfr_elast2)))
print("Test score: {:.2f}".format(rfr2.score(x_test_2, y_test_2))) # Скор для тестовой выборки

plt.figure(figsize=(10,5))
plt.title("Тестовые и прогнозные значения Random Forest Regressor")
plt.plot(y2_pred_forest, label = "Прогноз", color = "red")
plt.plot(y_test_2.values, label = "Тест", color = 'orange')
plt.xlabel("Количество наблюдений")
plt.ylabel("Модуль упругости при растяжении, ГПа")
plt.legend()
plt.grid(True);

#построение модели и вузуализация Линейной регрессии
lr2 = LinearRegression()
lr2.fit(x_train_2, y_train_2)
y_pred_lr2 = lr2.predict(x_test_2)
mae_lr2 = mean_absolute_error(y_pred_lr2, y_test_2)
mse_lin_elast2 = mean_squared_error(y_test_2, y_pred_lr2)
print('Linear Regression Results Train:') # Скор для тренировочной выборки
print("Test score: {:.2f}".format(lr2.score(x_train_2, y_train_2)))
print('Linear Regression Results:')    
print('lr_MAE: ', round(mean_absolute_error(y_test_2, y_pred_lr2)))
print('lr_MSE: {:.2f}'.format(mse_lin_elast2))
print("lr_RMSE: {:.2f}".format (np.sqrt(mse_lin_elast2)))
print("Test score: {:.2f}".format(lr2.score(x_test_2, y_test_2))) # Скор для тестовой выборки

plt.figure(figsize = (10, 5))
plt.title("Тестовые и прогнозные значения Linear Regression")
plt.plot(y_pred_lr2, label = "Прогноз", color = 'orange')
plt.plot(y_test_2.values, label = "Тест", color = 'cyan')
plt.xlabel("Количество наблюдений")
plt.ylabel("Модуль упругости при растяжении, ГПа")
plt.legend()
plt.grid(True);

error = y_test_2 - y_pred_lr2
plt.hist(error, bins = 25, color = "m")
plt.xlabel('Prediction Error')
_ = plt.ylabel('Count')

#Выводим гиперпараметры для оптимальной модели
print(gs21.best_estimator_)
gs121 = gs21.best_estimator_
print(f'R2-score KNR для модуля упругости при растяжении: {gs121.score(x_test_2, y_test_2).round(3)}')

new_row_in_mae_df = {'Регрессор': 'KNeighbors1_GridSearchCV', 'MAE': mae_knn21_grid} 

mae_df = mae_df.append(new_row_in_mae_df, ignore_index=True)
mae_df

#подставим оптимальные гиперпараметры в нашу модель метода деревья решений
dtr21_grid = DecisionTreeRegressor(criterion='poisson', max_depth=7, max_features='auto',
                      min_samples_leaf=100, min_samples_split=250)
#Обучаем модель
dtr21_grid.fit(x_train_2, y_train_2)

predictions_dtr21_grid = dtr21_grid.predict(x_test_2)
#Оцениваем точность на тестовом наборе
mae_dtr21_grid = mean_absolute_error(predictions_dtr21_grid, y_test_2)
mae_dtr21_grid

#Написать нейронную сеть, которая будет рекомендовать соотношение матрица-наполнитель.

# Сформируем входы и выход для модели

tv = df3_merged['Соотношение матрица-наполнитель']
tr_v = df3_merged.loc[:, df3_merged.columns != 'Соотношение матрица-наполнитель']

# Разбиваем выборки на обучающую и тестовую
x_train, x_test, y_train, y_test = train_test_split(tr_v, tv, test_size = 0.3, random_state = 14)

# Нормализуем данные

x_train_n = tf.keras.layers.Normalization(axis =-1)
x_train_n.adapt(np.array(x_train))

def create_model(lyrs=[32], act='softmax', opt='SGD', dr=0.1):
    
    seed = 7
    np.random.seed(seed)
    tf.random.set_seed(seed)
    
    model = Sequential()
    model.add(Dense(lyrs[0], input_dim=x_train.shape[1], activation=act)) 
    for i in range(1,len(lyrs)):
        model.add(Dense(lyrs[i], activation=act))
    
    model.add(Dropout(dr))
    model.add(Dense(3, activation='tanh'))  # выходной слой
    
    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['mae', 'accuracy'])
 
    return model

# строим модель
model = KerasClassifier(build_fn=create_model, verbose=0)

# определяем параметры
batch_size = [2, 10]
epochs = [10, 50]
param_grid = dict(batch_size=batch_size, epochs=epochs)

# поиск оптимальных параметров
grid = GridSearchCV(estimator=model, 
                    param_grid=param_grid,
                    cv=10,
                    verbose=1, n_jobs=-1)

grid_result = grid.fit(x_train, y_train)

# результаты
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

model = KerasClassifier(build_fn=create_model, epochs=30, batch_size=4, verbose=0)

optimizer = ['SGD', 'RMSprop', 'Adagrad']
param_grid = dict(opt=optimizer)

grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=10, verbose=2)
grid_result = grid.fit(x_train, y_train)

# результаты
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=4, verbose=0)

layers = [[8],[16, 4],[32, 8, 3],[12, 6, 3], [64, 64, 3], [92, 64, 16, 3]]
param_grid = dict(lyrs=layers)

grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=10, verbose=2)
grid_result = grid.fit(x_train, y_train)

# результаты
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

model = KerasClassifier(build_fn=create_model, epochs=30, batch_size=2, verbose=0)

activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']
param_grid = dict(act=activation)

grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=10)
grid_result = grid.fit(x_train, y_train)

# построение окончательной модели
model = create_model(lyrs=[92, 64, 16, 3], dr=0.05)

print(model.summary())

# обучаем нейросеть, 100/20 CV
model_hist = model.fit(x_train, 
    y_train, 
    epochs = 100, 
    verbose = 1, 
    validation_split = 0.2)

# оценим модель
scores = model.evaluate(x_test, y_test)
print("\n%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))

model_hist.history

# Посмотрим на график потерь на тренировочной и тестовой выборках
def model_loss_plot(model_hist):
    plt.figure(figsize = (17,5))
    plt.plot(model_hist.history['loss'],
             label = 'ошибка на обучающей выборке')
    plt.plot(model_hist.history['val_loss'],
            label = 'ошибка на тестовой выборке')
    plt.title('График потерь модели')
    plt.ylabel('Значение ошибки')
    plt.xlabel('Эпохи')
    plt.legend(['Oшибка на обучающей выборке', 'Ошибка на тестовой выборке'], loc='best')
    plt.show()
model_loss_plot(model_hist)

# Зададим функцию для визуализации факт/прогноз для результатов моделей
# Посмотрим на график результата работы модели
def actual_and_predicted_plot(orig, predict, var, model_name):    
    plt.figure(figsize=(17,5))
    plt.title(f'Тестовые и прогнозные значения: {model_name}')
    plt.plot(orig, label = 'Тест')
    plt.plot(predict, label = 'Прогноз')
    plt.legend(loc = 'best')
    plt.ylabel(var)
    plt.xlabel('Количество наблюдений')
    plt.show()
actual_and_predicted_plot(y_test.values, model.predict(x_test.values), 'Cоотношение матрица/наполнитель', 'Keras_neuronet')

"""Заключение

Стоит подвести итог и сказать, что машинное обучение в задачах моделей прогнозирования – довольно сложный процесс, требующий навыков программирования, и профессионального подхода к сфере самих композитных материалов.
 Необходимо понимать, на какие атрибуты нужно в первую очередь обратить внимание, чтобы суметь впоследствии грамотно и чётко спрогнозировать тот или иной признак. И, естественно, обладать всеми необходимыми знаниями, умениями и навыками для прогнозов и расчетов. 
 В ходе работы был задействован дата-сет с реальными данными, произведен сопутствующий анализ; построены разнообразные графики,осуществлено разбиение данных на обучающую и тестовую выборки, которая во многом облегчила процесс машинного обучения. 
 В рамках машинного обучения и поиска гиперпараметров были задействованы несколько алгоритмов: линейная регрессия, К ближайших соседей, деревья решений,случайный лес.
  Поиск гиперпараметров осуществлялся при помощи таких методов, как «GridSearch».Обучена нейронная сеть и разработано пользовательское приложение, предсказывающе вероятный прогноз по заданным параметрам. 

"""

